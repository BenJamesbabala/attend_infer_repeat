{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path as osp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sonnet as snt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from neurocity.tools.params import num_trainable_params\n",
    "\n",
    "from tf_tools.eval import make_expr_logger\n",
    "\n",
    "from data import load_data, tensors_from_data\n",
    "from model import AIRCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "img_size = 50, 50\n",
    "crop_size = 20, 20\n",
    "n_latent = 50\n",
    "n_hidden = 256\n",
    "n_steps = 3\n",
    "\n",
    "results_dir = '../results'\n",
    "run_name = 'sigmoid_scale_uniform_canvas_bias_lower_pres_weight2'\n",
    "\n",
    "logdir = osp.join(results_dir, run_name)\n",
    "checkpoint_name = osp.join(logdir, 'model.ckpt')\n",
    "axes = {'imgs': 0, 'labels': 0, 'nums': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data('mnist_test.pickle')\n",
    "train_data = load_data('mnist_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_data['imgs']\n",
    "nums = train_data['nums']\n",
    "\n",
    "fig, fig_axes = plt.subplots(8, 8, figsize=(32, 32))\n",
    "idx = np.random.choice(imgs.shape[0], 64)\n",
    "for i, ax in zip(idx, fig_axes.flatten()):\n",
    "    ax.imshow(imgs[i], cmap='gray')\n",
    "    num_str = ' '.join([str(n) for n in nums[:, i].squeeze()])\n",
    "    ax.set_title(num_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "train_tensors = tensors_from_data(train_data, batch_size, axes, shuffle=True)\n",
    "test_tensors = tensors_from_data(test_data, batch_size, axes, shuffle=False)\n",
    "x, test_x = train_tensors['imgs'], test_tensors['imgs']\n",
    "y, test_y = train_tensors['nums'], test_tensors['nums']\n",
    "\n",
    "transition = snt.LSTM(n_hidden)\n",
    "air = AIRCell(img_size, crop_size, n_latent, transition, max_crop_size=1.0)\n",
    "initial_state = air.initial_state(x)\n",
    "\n",
    "dummy_sequence = tf.zeros((n_steps, batch_size, 1), name='dummy_sequence')\n",
    "outputs, state = tf.nn.dynamic_rnn(air, dummy_sequence, initial_state=initial_state, time_major=True)\n",
    "canvas, cropped, what, where, presence_logit = outputs\n",
    "presence = tf.nn.sigmoid(presence_logit)\n",
    "\n",
    "cropped = tf.reshape(presence * tf.nn.sigmoid(cropped), (n_steps, batch_size,) + tuple(crop_size))\n",
    "canvas = tf.reshape(canvas, (n_steps, batch_size,) + tuple(img_size))\n",
    "prob_canvas = tf.nn.sigmoid(canvas)\n",
    "final_canvas = canvas[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print num_trainable_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = ((x - final_canvas)**2\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=x, logits=final_canvas)\n",
    "\n",
    "rec_loss = tf.reduce_mean(tf.reduce_sum(loss, axis=(1, 2)))\n",
    "tf.summary.scalar('rec_loss', rec_loss)\n",
    "\n",
    "alpha= 1.\n",
    "num_steps_penalty = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=presence_logit)\n",
    "num_steps_penalty = tf.reduce_mean(num_steps_penalty)\n",
    "tf.summary.scalar('steps_loss', num_steps_penalty)\n",
    "\n",
    "loss = rec_loss + alpha * num_steps_penalty\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "# opt = tf.train.AdamOptimizer(learning_rate)\n",
    "opt = tf.train.RMSPropOptimizer(learning_rate, momentum=.9, centered=True)\n",
    "train_step = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "all_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.FileWriter(logdir)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = train_data['imgs']\n",
    "presence_gt = train_data['nums']\n",
    "train_itr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_fig(checkpoint_dir, global_step):\n",
    "    xx, pred_canvas, pred_crop, pres = sess.run([x, prob_canvas, cropped, presence])\n",
    "\n",
    "    max_imgs = 10\n",
    "    bs = min(max_imgs, batch_size)\n",
    "    scale = 1.\n",
    "    figsize = scale * np.asarray((bs, 2 * n_steps + 1))\n",
    "    fig, axes = plt.subplots(2 * n_steps + 1, bs, figsize=figsize)\n",
    "\n",
    "    for i, ax in enumerate(axes[0]):\n",
    "        ax.imshow(xx[i], cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    for i, ax_row in enumerate(axes[1:1+n_steps]):\n",
    "        for j, ax in enumerate(ax_row):\n",
    "            ax.imshow(pred_canvas[i, j], cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    for i, ax_row in enumerate(axes[1+n_steps:]):\n",
    "        for j, ax in enumerate(ax_row):\n",
    "            ax.imshow(pred_crop[i, j], cmap='gray', vmin=0, vmax=1)\n",
    "            ax.set_title('{:.02f}'.format(pres[i, j, 0]), fontsize=4*scale)\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "    \n",
    "    fig_name = osp.join(checkpoint_dir, 'progress_fig_{}.png'.format(global_step))\n",
    "    fig.savefig(fig_name, dpi=300)\n",
    "    plt.close('all')\n",
    "    \n",
    "exprs = dict(loss=loss, rec_loss=rec_loss, steps_loss=num_steps_penalty)\n",
    "train_log = make_expr_logger(sess, summary_writer, train_data['imgs'].shape[0] / batch_size, exprs, name='train')\n",
    "test_log = make_expr_logger(sess, summary_writer, test_data['imgs'].shape[0] / batch_size, exprs, name='test', data_dict={x: test_x, y: test_y})\n",
    "\n",
    "def log(train_itr):\n",
    "    train_log(train_itr)\n",
    "    test_log(train_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log(train_itr)\n",
    "for train_itr in xrange(train_itr+1, int(1e7)):\n",
    "    \n",
    "    sess.run(train_step)       \n",
    "    if train_itr % 1000 == 0:\n",
    "        summaries = sess.run(all_summaries)\n",
    "        summary_writer.add_summary(summaries, train_itr)\n",
    "        \n",
    "    if train_itr % 1000 == 0:\n",
    "        log(train_itr)\n",
    "        \n",
    "    if train_itr % 1000 == 0:\n",
    "#         saver.save(sess, checkpoint_name, global_step=train_itr)\n",
    "        make_fig(logdir, train_itr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
