{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path as osp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sonnet as snt\n",
    "\n",
    "from tensorflow.contrib.distributions import Bernoulli\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from neurocity import minimize_clipped\n",
    "from neurocity.tools.params import num_trainable_params\n",
    "\n",
    "from tf_tools.eval import make_expr_logger\n",
    "\n",
    "from data import load_data, tensors_from_data\n",
    "from model import AIRCell\n",
    "from ops import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "img_size = 50, 50\n",
    "crop_size = 20, 20\n",
    "n_latent = 50\n",
    "n_hidden = 256\n",
    "n_steps = 3\n",
    "\n",
    "results_dir = '../results'\n",
    "run_name = 'discrete'\n",
    "\n",
    "logdir = osp.join(results_dir, run_name)\n",
    "checkpoint_name = osp.join(logdir, 'model.ckpt')\n",
    "axes = {'imgs': 0, 'labels': 0, 'nums': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_weight = 0\n",
    "\n",
    "num_steps_prior = 0.\n",
    "latent_code_prior = None\n",
    "\n",
    "use_reinforce = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = load_data('mnist_test.pickle')\n",
    "train_data = load_data('mnist_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = train_data['imgs']\n",
    "# nums = train_data['nums']\n",
    "\n",
    "# fig, fig_axes = plt.subplots(8, 8, figsize=(32, 32))\n",
    "# idx = np.random.choice(imgs.shape[0], 64)\n",
    "# for i, ax in zip(idx, fig_axes.flatten()):\n",
    "#     ax.imshow(imgs[i], cmap='gray')\n",
    "#     num_str = ' '.join([str(n) for n in nums[:, i].squeeze()])\n",
    "#     ax.set_title(num_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "train_tensors = tensors_from_data(train_data, batch_size, axes, shuffle=True)\n",
    "test_tensors = tensors_from_data(test_data, batch_size, axes, shuffle=False)\n",
    "x, test_x = train_tensors['imgs'], test_tensors['imgs']\n",
    "y, test_y = train_tensors['nums'], test_tensors['nums']\n",
    "\n",
    "transition = snt.LSTM(n_hidden)\n",
    "air = AIRCell(img_size, crop_size, n_latent, transition, max_crop_size=1.0,\n",
    "              presence_bias=1.,\n",
    "              explore_eps=.0,\n",
    "              debug=True)\n",
    "\n",
    "initial_state = air.initial_state(x)\n",
    "\n",
    "dummy_sequence = tf.zeros((n_steps, batch_size, 1), name='dummy_sequence')\n",
    "outputs, state = tf.nn.dynamic_rnn(air, dummy_sequence, initial_state=initial_state, time_major=True)\n",
    "canvas, cropped, what, where, presence_logit, presence = outputs\n",
    "presence_prob = tf.nn.sigmoid(presence_logit)\n",
    "\n",
    "with tf.variable_scope('notebook'):\n",
    "    cropped = tf.reshape(presence * tf.nn.sigmoid(cropped), (n_steps, batch_size,) + tuple(crop_size))\n",
    "    canvas = tf.reshape(canvas, (n_steps, batch_size,) + tuple(img_size))\n",
    "    prob_canvas = tf.nn.sigmoid(canvas)\n",
    "    final_canvas = canvas[-1]\n",
    "    \n",
    "    \n",
    "with tf.variable_scope('baseline'):\n",
    "    baseline = snt.TrainableVariable([], initializers={'w': tf.zeros_initializer()}, name='constant_baseline')\n",
    "    \n",
    "baseline_tensor = baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990483.0\n"
     ]
    }
   ],
   "source": [
    "print num_trainable_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###    Loss #################################################################################\n",
    "loss = Loss()\n",
    "prior_loss = Loss()\n",
    "\n",
    "###    Reconstruction Loss ##################################################################\n",
    "rec_loss_per_sample = tf.nn.sigmoid_cross_entropy_with_logits(labels=x, logits=final_canvas)\n",
    "rec_loss_per_sample = tf.reduce_sum(rec_loss_per_sample, axis=(1, 2))\n",
    "rec_loss = tf.reduce_mean(rec_loss_per_sample)\n",
    "tf.summary.scalar('rec_loss', rec_loss)\n",
    "\n",
    "loss.add(rec_loss, rec_loss_per_sample)\n",
    "# # ###    Prior Loss ###########################################################################\n",
    "\n",
    "if prior_weight > 0.:\n",
    "    \n",
    "    if num_steps_prior is not None:    \n",
    "        num_steps_prior_loss_per_sample = tf.squeeze((tf.reduce_sum(presence, 0) - num_steps_prior) ** 2)\n",
    "        num_steps_prior_loss = tf.reduce_mean(num_steps_prior_loss_per_sample)\n",
    "        tf.summary.scalar('num_steps_prior_loss', num_steps_prior_loss)\n",
    "\n",
    "        prior_loss.add(num_steps_prior_loss, num_steps_prior_loss_per_sample)\n",
    "\n",
    "\n",
    "    if latent_code_prior is not None:\n",
    "        latent_code_prior_loss_per_sample = tf.reduce_mean(tf.reduce_sum((what - latent_code_prior) ** 2, -1), 0)\n",
    "        latent_code_prior_loss = tf.reduce_mean(latent_code_prior_loss_per_sample)\n",
    "        tf.summary.scalar('latent_code_prior_loss', latent_code_prior_loss)\n",
    "\n",
    "        prior_loss.add(latent_code_prior_loss, latent_code_prior_loss_per_sample)\n",
    "\n",
    "    tf.summary.scalar('prior_loss', prior_loss._value)\n",
    "    loss.add(prior_loss, weight=prior_weight)\n",
    "\n",
    "# ###   REINFORCE ############################################################################\n",
    "\n",
    "opt_loss = loss.value\n",
    "if use_reinforce:\n",
    "    # clipped_presence_prob = tf.clip_by_value(presence_prob, 1e-7, 1. - 1e-7)\n",
    "    # log_prob = Bernoulli(probs=clipped_presence_prob).log_prob(presence)\n",
    "    # log_prob = tf.squeeze(tf.reduce_mean(log_prob, 0))\n",
    "\n",
    "    # instead of maximising probability we'll minimise cross-entropy, where labels are the taken actions\n",
    "    log_prob = tf.nn.sigmoid_cross_entropy_with_logits(labels=presence, logits=presence_logit)\n",
    "\n",
    "    importance_weight = loss._per_sample\n",
    "    importance_weight -= baseline()\n",
    "\n",
    "    reinforce_loss_per_sample = tf.stop_gradient(importance_weight) * log_prob\n",
    "    reinforce_loss = tf.reduce_mean(reinforce_loss_per_sample)\n",
    "    tf.summary.scalar('reinforce_loss', reinforce_loss)\n",
    "\n",
    "    opt_loss -= reinforce_loss\n",
    "\n",
    "    \n",
    "    \n",
    "### Optimizer #################################################################################\n",
    "lr_tensor = tf.Variable(learning_rate, name='learning_rate', trainable=False)\n",
    "opt = tf.train.RMSPropOptimizer(lr_tensor, momentum=.9, centered=True)\n",
    "# true_train_step = opt.minimize(opt_loss)\n",
    "true_train_step = minimize_clipped(opt, opt_loss, clip_value=.3, normalize_by_num_params=True)\n",
    "\n",
    "# # ### Baseline Optimisation ##################################################################################\n",
    "baseline_target = loss.value\n",
    "baseline_loss = (baseline_target - baseline()) ** 2\n",
    "tf.summary.scalar('baseline_loss', baseline_loss)\n",
    "\n",
    "baseline_opt = tf.train.RMSPropOptimizer(10 * lr_tensor, momentum=.9, centered=True)\n",
    "baseline_train_step = baseline_opt.minimize(baseline_loss)\n",
    "\n",
    "###    Train Step ##############################################################################\n",
    "train_step = [true_train_step, baseline_train_step]\n",
    "\n",
    "###    Metrics #################################################################################\n",
    "gt_num = tf.reduce_sum(y, 0)\n",
    "pred_num = tf.reduce_sum(presence, 0)\n",
    "num_step_accuracy = tf.reduce_mean(tf.to_float(tf.equal(gt_num, pred_num)))\n",
    "num_step = tf.reduce_mean(tf.to_float(pred_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping baseline/constant_baseline/w:0\n"
     ]
    }
   ],
   "source": [
    "vs = tf.trainable_variables()\n",
    "if 'baseline' in locals():\n",
    "    vs = list(set(vs) - set([baseline]))\n",
    "gs = tf.gradients(opt_loss, vs)\n",
    "\n",
    "for v, g in zip(vs, gs):\n",
    "    if g is None:\n",
    "        print 'Skipping', v.name\n",
    "    else:\n",
    "        assert v.get_shape() == g.get_shape(), v.name\n",
    "\n",
    "named_grads = {v.name: g for v, g in zip(vs, gs) if g is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_variance(n=10, sort_by_var=True):\n",
    "    gs = {k: [] for k in named_grads}\n",
    "    for i in xrange(n):\n",
    "        values = sess.run(named_grads)\n",
    "        for k, v in values.iteritems():\n",
    "            gs[k].append(v)\n",
    "\n",
    "    for k, v in gs.iteritems():\n",
    "        v = np.stack(v, 0).reshape((n, -1))\n",
    "        gs[k] = np.var(v, 0).mean()\n",
    "        \n",
    "    sort_idx = 1 if sort_by_var else 0\n",
    "    gs = sorted(gs.items(), key=lambda x: x[sort_idx], reverse=True)\n",
    "    return gs\n",
    "\n",
    "def print_grad_variance():\n",
    "    grad_vars = grad_variance(10)\n",
    "    print\n",
    "    for g in grad_vars:\n",
    "        if g[1] > 1e-2:\n",
    "            print g\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "all_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.FileWriter(logdir)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = train_data['imgs']\n",
    "presence_gt = train_data['nums']\n",
    "train_itr = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_fig(checkpoint_dir, global_step):\n",
    "    xx, pred_canvas, pred_crop, pres = sess.run([x, prob_canvas, cropped, presence])\n",
    "\n",
    "    max_imgs = 10\n",
    "    bs = min(max_imgs, batch_size)\n",
    "    scale = 1.\n",
    "    figsize = scale * np.asarray((bs, 2 * n_steps + 1))\n",
    "    fig, axes = plt.subplots(2 * n_steps + 1, bs, figsize=figsize)\n",
    "\n",
    "    for i, ax in enumerate(axes[0]):\n",
    "        ax.imshow(xx[i], cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    for i, ax_row in enumerate(axes[1:1+n_steps]):\n",
    "        for j, ax in enumerate(ax_row):\n",
    "            ax.imshow(pred_canvas[i, j], cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "    for i, ax_row in enumerate(axes[1+n_steps:]):\n",
    "        for j, ax in enumerate(ax_row):\n",
    "            ax.imshow(pred_crop[i, j], cmap='gray', vmin=0, vmax=1)\n",
    "            ax.set_title('{:.02f}'.format(pres[i, j, 0]), fontsize=4*scale)\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "    \n",
    "    fig_name = osp.join(checkpoint_dir, 'progress_fig_{}.png'.format(global_step))\n",
    "    fig.savefig(fig_name, dpi=300)\n",
    "    plt.close('all')\n",
    "    \n",
    "exprs = {\n",
    "#     'loss': loss,\n",
    "    'rec_loss': rec_loss,\n",
    "    'prior_loss': prior_loss.value,\n",
    "    'reinforce_loss': reinforce_loss,\n",
    "    'baseline_loss': baseline_loss,\n",
    "    'num_step_acc': num_step_accuracy,\n",
    "    'num_step': num_step\n",
    "}\n",
    "train_log = make_expr_logger(sess, summary_writer, train_data['imgs'].shape[0] / batch_size, exprs, name='train')\n",
    "test_log = make_expr_logger(sess, summary_writer, test_data['imgs'].shape[0] / batch_size, exprs, name='test', data_dict={x: test_x, y: test_y})\n",
    "\n",
    "def log(train_itr):\n",
    "    train_log(train_itr)\n",
    "    test_log(train_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Data train prior_loss = 0.0000, baseline_loss = 265755.3693, reinforce_loss = 296.3327, rec_loss = 512.4475, num_step = 2.2046, num_step_acc = 0.1993, eval time = 17.28s\n",
      "Step 0, Data test prior_loss = 0.0000, baseline_loss = 235370.5521, reinforce_loss = 283.1625, rec_loss = 485.1533, num_step = 2.1885, num_step_acc = 0.1917, eval time = 0.3637s\n",
      "baseline value = 0.00333332177252\n",
      "\n",
      "(u'AIRCell/presence/linear_1/b:0', 476.58575)\n",
      "(u'AIRCell/canvas_value:0', 13.716306)\n",
      "(u'AIRCell/presence/linear/b:0', 8.7405243)\n",
      "(u'AIRCell/presence/linear_1/w:0', 0.41233018)\n",
      "(u'AIRCell/Encoder/linear/b:0', 0.33140901)\n",
      "(u'lstm_initial_state_1/w:0', 0.13984928)\n",
      "(u'AIRCell/rnn_inpt/linear/b:0', 0.11753002)\n",
      "(u'AIRCell/Encoder/linear_1/b:0', 0.10108509)\n",
      "(u'lstm/b_gates:0', 0.10018014)\n",
      "(u'AIRCell/Encoder_1/linear_1/b:0', 0.085266963)\n",
      "(u'where_init:0', 0.049342848)\n",
      "(u'AIRCell/Encoder_1/linear/b:0', 0.043961104)\n",
      "(u'lstm_initial_state_0/w:0', 0.022068784)\n",
      "(u'AIRCell/Decoder/linear/b:0', 0.020463252)\n",
      "(u'what_init:0', 0.015224807)\n",
      "\n",
      "Step 1000, Data train prior_loss = 0.0000, baseline_loss = 913.8438, reinforce_loss = 6.7362, rec_loss = 77.3744, num_step = 2.5363, num_step_acc = 0.1237, eval time = 22.18s\n",
      "Step 1000, Data test prior_loss = 0.0000, baseline_loss = 619.0794, reinforce_loss = 5.9272, rec_loss = 73.2814, num_step = 2.5104, num_step_acc = 0.1167, eval time = 0.3725s\n",
      "baseline value = 48.4185676575\n",
      "\n",
      "(u'AIRCell/canvas_value:0', 11.851915)\n",
      "(u'AIRCell/presence/linear_1/w:0', 1.15976)\n",
      "(u'AIRCell/presence/linear_1/b:0', 0.51462591)\n",
      "(u'AIRCell/TransformParam/linear_1/w:0', 0.47313443)\n",
      "(u'AIRCell/Encoder_1/linear_1/b:0', 0.24208803)\n",
      "(u'AIRCell/Decoder/linear/b:0', 0.1020643)\n",
      "(u'AIRCell/Encoder_1/linear/b:0', 0.091753222)\n",
      "(u'AIRCell/Encoder_1/linear_1/w:0', 0.048328295)\n",
      "(u'AIRCell/Decoder/linear/w:0', 0.029505609)\n",
      "\n",
      "Step 2000, Data train prior_loss = 0.0000, baseline_loss = 22805.9804, reinforce_loss = 33.8983, rec_loss = 232.1756, num_step = 0.2137, num_step_acc = 0.3353, eval time = 22.38s\n",
      "Step 2000, Data test prior_loss = 0.0000, baseline_loss = 20027.1241, reinforce_loss = 30.8473, rec_loss = 224.2195, num_step = 0.1958, num_step_acc = 0.3438, eval time = 0.3696s\n",
      "baseline value = 82.7982025146\n",
      "\n",
      "(u'AIRCell/canvas_value:0', 32.631706)\n",
      "(u'AIRCell/presence/linear_1/w:0', 7.2678437)\n",
      "(u'AIRCell/presence/linear_1/b:0', 4.2546353)\n",
      "(u'AIRCell/TransformParam/linear_1/w:0', 0.70859754)\n",
      "(u'AIRCell/Encoder/linear/b:0', 0.16291167)\n",
      "(u'AIRCell/Encoder_1/linear_1/b:0', 0.1031784)\n",
      "(u'AIRCell/Encoder_1/linear/b:0', 0.085951149)\n",
      "(u'lstm/w_gates:0', 0.048175324)\n",
      "(u'AIRCell/Decoder/linear/b:0', 0.04540569)\n",
      "(u'AIRCell/Encoder_1/linear_1/w:0', 0.043049254)\n",
      "(u'AIRCell/Decoder/linear/w:0', 0.033413295)\n",
      "(u'AIRCell/presence/linear/b:0', 0.022613324)\n",
      "(u'AIRCell/presence/linear/w:0', 0.015468087)\n",
      "(u'lstm_initial_state_1/w:0', 0.014907716)\n",
      "\n",
      "Step 3000, Data train prior_loss = 0.0000, baseline_loss = 732.7273, reinforce_loss = 0.1710, rec_loss = 146.4690, num_step = 2.9965, num_step_acc = 0.0008, eval time = 22.41s\n",
      "Step 3000, Data test prior_loss = 0.0000, baseline_loss = 98.1779, reinforce_loss = 0.0998, rec_loss = 135.9674, num_step = 2.9958, num_step_acc = 0.0010, eval time = 0.3781s\n",
      "baseline value = 126.063812256\n",
      "\n",
      "(u'AIRCell/canvas_value:0', 21.954752)\n",
      "(u'AIRCell/TransformParam/linear_1/w:0', 3.9788451)\n",
      "(u'AIRCell/Encoder_1/linear/b:0', 0.34610367)\n",
      "(u'AIRCell/Encoder_1/linear_1/b:0', 0.31797057)\n",
      "(u'AIRCell/Decoder/linear/b:0', 0.23311381)\n",
      "(u'AIRCell/Decoder/linear/w:0', 0.15873113)\n",
      "(u'AIRCell/Encoder_1/linear_1/w:0', 0.13516709)\n",
      "(u'lstm_initial_state_1/w:0', 0.047691219)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_itr in xrange(train_itr+1, int(1e7)):\n",
    "        \n",
    "    sess.run(train_step)\n",
    "    if train_itr % 1000 == 0:\n",
    "        summaries = sess.run(all_summaries)\n",
    "        summary_writer.add_summary(summaries, train_itr)\n",
    "        \n",
    "    if train_itr % 1000 == 0:\n",
    "        log(train_itr)\n",
    "        \n",
    "    if train_itr % 1000 == 0:\n",
    "#         saver.save(sess, checkpoint_name, global_step=train_itr)\n",
    "        make_fig(logdir, train_itr)    \n",
    "    \n",
    "    if train_itr % 1000 == 0:\n",
    "        print 'baseline value = {}'.format(sess.run(baseline_tensor))\n",
    "        print_grad_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# named_outputs = {\n",
    "#     'canvas': canvas,\n",
    "#     'cropped': cropped,\n",
    "#     'what': what,\n",
    "#     'where': where, \n",
    "#     'presence_logit': presence_logit,\n",
    "#     'presence': presence,\n",
    "#     'rec_loss': rec_loss,\n",
    "#     'imp_weight': importance_weight,\n",
    "#     'log_prob': log_prob,\n",
    "#     'baseline_loss': baseline_loss,\n",
    "#     'clipped_pres': clipped_presence_prob,\n",
    "#     'pres_prob': presence_prob\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.distributions.python.ops import kullback_leibler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in kullback_leibler._DIVERGENCES:\n",
    "    print d[0].__name__, d[1].__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in exprs:\n",
    "    print e, exprs[e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ee = sess.run(exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_tensor = baseline()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
